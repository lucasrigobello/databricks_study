{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "441552f3-e1b0-4b37-bfda-495eceded0ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Churn Prediction Feature Engineering\n",
    "\n",
    "<img src=\"https://github.com/RafiKurlansik/laughing-garbanzo/blob/main/step1.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e18c7a8e-f361-4aca-946e-c9d99e425a27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Featurization Logic\n",
    "\n",
    "This is a fairly clean dataset so we'll just do some one-hot encoding, and clean up the column names afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38862304-043a-4a65-a8b1-567111bb071c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in Bronze Delta table using Spark"
    }
   },
   "outputs": [],
   "source": [
    "# Read into Spark\n",
    "telcoDF = spark.table(\"workspace.databricks_study.telco_customer_churn\")\n",
    "\n",
    "display(telcoDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2952e02-f7e8-47d7-bddb-155e86049947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using `koalas` allows us to scale `pandas` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb7ebc5a-5486-4fe9-89bc-a05b606309d2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define featurization function"
    }
   },
   "outputs": [],
   "source": [
    "# import databricks.koalas as ks\n",
    "import pyspark.pandas as ks\n",
    "\n",
    "def compute_churn_features(data):\n",
    "  \n",
    "  # Convert to koalas\n",
    "  # data = data.to_koalas()\n",
    "  data = ks.DataFrame(data)\n",
    "  \n",
    "  # OHE\n",
    "  data = ks.get_dummies(data, \n",
    "                        columns=['gender', 'partner', 'dependents',\n",
    "                                 'phoneService', 'multipleLines', 'internetService',\n",
    "                                 'onlineSecurity', 'onlineBackup', 'deviceProtection',\n",
    "                                 'techSupport', 'streamingTV', 'streamingMovies',\n",
    "                                 'contract', 'paperlessBilling', 'paymentMethod'],dtype = 'int64')\n",
    "  \n",
    "  # Convert label to int and rename column\n",
    "  data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})\n",
    "  data = data.astype({'Churn': 'int32'})\n",
    "  # data = data.rename(columns = {'churnString': 'churn'})\n",
    "  \n",
    "  # Clean up column names\n",
    "  data.columns = data.columns.str.replace(' ', '')\n",
    "  data.columns = data.columns.str.replace('(', '-')\n",
    "  data.columns = data.columns.str.replace(')', '')\n",
    "  \n",
    "  # Drop missing values\n",
    "  data = data.dropna()\n",
    "  \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9d39eb-a449-4b56-aa68-13b10ece2ac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4778da01-fb49-42d9-98b8-d98ad9b69e30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d14fb140-d183-451d-b3c0-af0cbfc07ff5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = ks.DataFrame(telcoDF)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0fc54ac-64f0-4175-9827-0158595701ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df = ks.get_dummies(data, \n",
    "                        columns=['gender', 'partner', 'dependents',\n",
    "                                 'phoneService', 'multipleLines', 'internetService',\n",
    "                                 'onlineSecurity', 'onlineBackup', 'deviceProtection',\n",
    "                                 'techSupport', 'streamingTV', 'streamingMovies',\n",
    "                                 'contract', 'paperlessBilling', 'paymentMethod'],dtype = 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39de8f0e-7cca-4749-b981-4b7d8da3c428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36ca24a9-ff31-4f5c-971d-df00ab570ca5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write features to the feature store"
    }
   },
   "outputs": [],
   "source": [
    "# from databricks.feature_store import FeatureStoreClient\n",
    "# from databricks.feature_store import feature_table\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "fs = FeatureEngineeringClient()\n",
    "\n",
    "churn_features_df = compute_churn_features(telcoDF)\n",
    "\n",
    "churn_feature_table = fs.create_table(\n",
    "  name='workspace.databricks_study.churn_features',\n",
    "  primary_keys='customerID',\n",
    "  schema=churn_features_df.spark.schema(),\n",
    "  description='These features are derived from the sr_ibm_telco_churn table in the lakehouse.  I created dummy variables for the categorical columns, cleaned up their names, and added a boolean flag for whether the customer churned or not.  No aggregations were performed.'\n",
    ")\n",
    "\n",
    "fs.write_table(df=churn_features_df.to_spark(), name='workspace.databricks_study.churn_features', mode='merge')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_feature_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
